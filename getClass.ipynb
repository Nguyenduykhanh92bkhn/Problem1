{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You may be trying to read with python 3 a joblib pickle generated with python 2. This feature is not supported by joblib.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/numpy_pickle_compat.py\u001b[0m in \u001b[0;36mload_compatibility\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mload_short_binstring\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSHORT_BINSTRING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_short_binstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_decode_string\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xf3 in position 0: ordinal not in range(128)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bb0a2b502e6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Load the classifier, class names, scaler, number of clusters and vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdSlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bof.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Get the path of the testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    594\u001b[0m                     \u001b[0;31m# try to load a pickle file generated with an version of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m                     \u001b[0;31m# Joblib so we load it with joblib compatibility function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/numpy_pickle_compat.py\u001b[0m in \u001b[0;36mload_compatibility\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    233\u001b[0m                     'This feature is not supported by joblib.')\n\u001b[1;32m    234\u001b[0m                 \u001b[0mnew_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mnew_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpickler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'file_handle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You may be trying to read with python 3 a joblib pickle generated with python 2. This feature is not supported by joblib."
     ]
    }
   ],
   "source": [
    "#!/usr/local/bin/python2.7\n",
    "\n",
    "import argparse as ap\n",
    "import cv2\n",
    "import imutils \n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.externals import joblib\n",
    "from scipy.cluster.vq import *\n",
    "\n",
    "# Load the classifier, class names, scaler, number of clusters and vocabulary \n",
    "clf, classes_names, stdSlr, k, voc = joblib.load(\"bof.pkl\")\n",
    "\n",
    "# Get the path of the testing set\n",
    "parser = ap.ArgumentParser()\n",
    "group = parser.add_mutually_exclusive_group(required=True)\n",
    "group.add_argument(\"-t\", \"--testingSet\", help=\"Path to testing Set\")\n",
    "group.add_argument(\"-i\", \"--image\", help=\"Path to image\")\n",
    "parser.add_argument('-v',\"--visualize\", action='store_true')\n",
    "args = vars(parser.parse_args())\n",
    "\n",
    "# Get the path of the testing image(s) and store them in a list\n",
    "image_paths = []\n",
    "if args[\"testingSet\"]:\n",
    "    test_path = args[\"testingSet\"]\n",
    "    try:\n",
    "        testing_names = os.listdir(test_path)\n",
    "    except OSError:\n",
    "        print (\"No such directory {}\\nCheck if the file exists\".format(test_path))\n",
    "        exit()\n",
    "    for testing_name in testing_names:\n",
    "        dir = os.path.join(test_path, testing_name)\n",
    "        class_path = imutils.imlist(dir)\n",
    "        image_paths+=class_path\n",
    "else:\n",
    "    image_paths = [args[\"image\"]]\n",
    "    \n",
    "# Create feature extraction and keypoint detector objects\n",
    "fea_det = cv2.FeatureDetector_create(\"SIFT\")\n",
    "des_ext = cv2.DescriptorExtractor_create(\"SIFT\")\n",
    "\n",
    "# List where all the descriptors are stored\n",
    "des_list = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "    im = cv2.imread(image_path)\n",
    "    if im == None:\n",
    "        print (\"No such file {}\\nCheck if the file exists\".format(image_path))\n",
    "        exit()\n",
    "    kpts = fea_det.detect(im)\n",
    "    kpts, des = des_ext.compute(im, kpts)\n",
    "    des_list.append((image_path, des))   \n",
    "    \n",
    "# Stack all the descriptors vertically in a numpy array\n",
    "descriptors = des_list[0][1]\n",
    "for image_path, descriptor in des_list[0:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor)) \n",
    "\n",
    "# \n",
    "test_features = np.zeros((len(image_paths), k), \"float32\")\n",
    "for i in xrange(len(image_paths)):\n",
    "    words, distance = vq(des_list[i][1],voc)\n",
    "    for w in words:\n",
    "        test_features[i][w] += 1\n",
    "\n",
    "# Perform Tf-Idf vectorization\n",
    "nbr_occurences = np.sum( (test_features > 0) * 1, axis = 0)\n",
    "idf = np.array(np.log((1.0*len(image_paths)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "# Scale the features\n",
    "test_features = stdSlr.transform(test_features)\n",
    "\n",
    "# Perform the predictions\n",
    "predictions =  [classes_names[i] for i in clf.predict(test_features)]\n",
    "\n",
    "# Visualize the results, if \"visualize\" flag set to true by the user\n",
    "if args[\"visualize\"]:\n",
    "    for image_path, prediction in zip(image_paths, predictions):\n",
    "        image = cv2.imread(image_path)\n",
    "        cv2.namedWindow(\"Image\", cv2.WINDOW_NORMAL)\n",
    "        pt = (0, 3 * image.shape[0] // 4)\n",
    "        cv2.putText(image, prediction, pt ,cv2.FONT_HERSHEY_SCRIPT_COMPLEX, 2, [0, 255, 0], 2)\n",
    "        cv2.imshow(\"Image\", image)\n",
    "        cv2.waitKey(3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
